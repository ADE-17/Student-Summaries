{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "prompts_train = pd.read_csv(\"../data/prompts_train.csv\")\n",
    "summaries_train = pd.read_csv(\"../data/summaries_train.csv\")\n",
    "\n",
    "# Drop student_id column from summaries_train and summaries_test\n",
    "summaries_train = summaries_train.drop(columns=['student_id'])\n",
    "summaries_train = summaries_train[:500]\n",
    "id_mapping = {id_val: idx for idx, id_val in enumerate(prompts_train['prompt_id'].unique())}\n",
    "\n",
    "summaries_train['prompt_id'] = summaries_train['prompt_id'].replace(id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob pyspellchecker\n",
    "# !pip install symspellpy\n",
    "# !pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from autocorrect import Speller\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()  # This initializes tqdm for pandas\n",
    "\n",
    "# Initialize SymSpell\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = \"path_to_frequency_dictionary.txt\"  # Replace this with your frequency dictionary path\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "\n",
    "# Initialize AutoCorrect\n",
    "autocorrect_spell = Speller(lang='en')\n",
    "\n",
    "def evaluate_textblob(text):\n",
    "    tb = TextBlob(text)\n",
    "    corrected_text = tb.correct().string\n",
    "    errors = sum(1 for orig, corr in zip(text.split(), corrected_text.split()) if orig != corr)\n",
    "    return errors\n",
    "\n",
    "def evaluate_pyspellchecker(text):\n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(text.split())\n",
    "    return len(misspelled)\n",
    "\n",
    "def evaluate_symspell(text):\n",
    "    # Get suggestions\n",
    "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
    "    # We return the difference between the original and suggested as errors\n",
    "    errors = sum(1 for orig, corr in zip(text.split(), suggestions[0].term.split()) if orig != corr)\n",
    "    return errors\n",
    "\n",
    "def evaluate_autocorrect(text):\n",
    "    corrected_text = autocorrect_spell(text)\n",
    "    errors = sum(1 for orig, corr in zip(text.split(), corrected_text.split()) if orig != corr)\n",
    "    return errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n",
      "100%|██████████| 500/500 [00:26<00:00, 18.98it/s]\n",
      "100%|██████████| 500/500 [00:35<00:00, 14.04it/s]\n",
      "100%|██████████| 500/500 [00:44<00:00, 11.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the functions and monitor progress\n",
    "summaries_train['textblob_errors'] = summaries_train['text'].progress_apply(evaluate_textblob)\n",
    "summaries_train['pyspellchecker_errors'] = summaries_train['text'].progress_apply(evaluate_pyspellchecker)\n",
    "summaries_train['symspell_errors'] = summaries_train['text'].progress_apply(evaluate_symspell)\n",
    "summaries_train['autocorrect_errors'] = summaries_train['text'].progress_apply(evaluate_autocorrect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train.to_csv(\"../data/summaries_train_with_spellcheck_errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        wording   content\n",
      "textblob_errors        0.411795  0.574385\n",
      "pyspellchecker_errors  0.487511  0.732595\n",
      "symspell_errors        0.373476  0.585821\n",
      "autocorrect_errors     0.240791  0.426653\n",
      "wording                1.000000  0.790635\n",
      "content                0.790635  1.000000\n"
     ]
    }
   ],
   "source": [
    "correlations = summaries_train[['textblob_errors', 'pyspellchecker_errors', 'symspell_errors', 'autocorrect_errors', 'wording', 'content']].corr()\n",
    "print(correlations[['wording', 'content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   wording   content\n",
      "normalized_textblob_errors       -0.028231 -0.075574\n",
      "normalized_pyspellchecker_errors -0.070670 -0.002601\n",
      "normalized_symspell_errors        0.181957  0.321365\n",
      "normalized_autocorrect_errors    -0.107153 -0.112457\n",
      "wording                           1.000000  0.790635\n",
      "content                           0.790635  1.000000\n"
     ]
    }
   ],
   "source": [
    "summaries_train['text_length'] = summaries_train['text'].apply(len)\n",
    "summaries_train['normalized_textblob_errors'] = summaries_train['textblob_errors'] / summaries_train['text_length']\n",
    "summaries_train['normalized_pyspellchecker_errors'] = summaries_train['pyspellchecker_errors'] / summaries_train['text_length']\n",
    "summaries_train['normalized_symspell_errors'] = summaries_train['symspell_errors'] / summaries_train['text_length']\n",
    "summaries_train['normalized_autocorrect_errors'] = summaries_train['autocorrect_errors'] / summaries_train['text_length']\n",
    "\n",
    "\n",
    "normalized_correlations_extended = summaries_train[['normalized_textblob_errors', 'normalized_pyspellchecker_errors', 'normalized_symspell_errors', 'normalized_autocorrect_errors', 'wording', 'content']].corr()\n",
    "print(normalized_correlations_extended[['wording', 'content']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
