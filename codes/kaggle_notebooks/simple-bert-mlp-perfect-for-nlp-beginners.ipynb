{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69af4a3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-18T21:29:34.929733Z",
     "iopub.status.busy": "2023-08-18T21:29:34.929339Z",
     "iopub.status.idle": "2023-08-18T21:29:34.944014Z",
     "shell.execute_reply": "2023-08-18T21:29:34.942683Z"
    },
    "papermill": {
     "duration": 0.027377,
     "end_time": "2023-08-18T21:29:34.946026",
     "exception": false,
     "start_time": "2023-08-18T21:29:34.918649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527f498",
   "metadata": {
    "papermill": {
     "duration": 0.008706,
     "end_time": "2023-08-18T21:29:34.963668",
     "exception": false,
     "start_time": "2023-08-18T21:29:34.954962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BERT + Multi-layer Perceptron! Do upvote - motivates me to write more such notebooks for novice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279e52b",
   "metadata": {
    "papermill": {
     "duration": 0.008494,
     "end_time": "2023-08-18T21:29:34.981136",
     "exception": false,
     "start_time": "2023-08-18T21:29:34.972642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Simple implementation for begineers! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3a779c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:29:34.999883Z",
     "iopub.status.busy": "2023-08-18T21:29:34.999601Z",
     "iopub.status.idle": "2023-08-18T21:29:49.031479Z",
     "shell.execute_reply": "2023-08-18T21:29:49.030512Z"
    },
    "papermill": {
     "duration": 14.043983,
     "end_time": "2023-08-18T21:29:49.033982",
     "exception": false,
     "start_time": "2023-08-18T21:29:34.989999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5d9ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:29:49.054400Z",
     "iopub.status.busy": "2023-08-18T21:29:49.053584Z",
     "iopub.status.idle": "2023-08-18T21:29:49.139098Z",
     "shell.execute_reply": "2023-08-18T21:29:49.138104Z"
    },
    "papermill": {
     "duration": 0.097676,
     "end_time": "2023-08-18T21:29:49.141218",
     "exception": false,
     "start_time": "2023-08-18T21:29:49.043542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c3f47",
   "metadata": {
    "papermill": {
     "duration": 0.009099,
     "end_time": "2023-08-18T21:29:49.159583",
     "exception": false,
     "start_time": "2023-08-18T21:29:49.150484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importing data into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945bc1f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:29:49.179257Z",
     "iopub.status.busy": "2023-08-18T21:29:49.178436Z",
     "iopub.status.idle": "2023-08-18T21:29:49.312191Z",
     "shell.execute_reply": "2023-08-18T21:29:49.311235Z"
    },
    "papermill": {
     "duration": 0.146024,
     "end_time": "2023-08-18T21:29:49.314505",
     "exception": false,
     "start_time": "2023-08-18T21:29:49.168481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94657ee5",
   "metadata": {
    "papermill": {
     "duration": 0.009031,
     "end_time": "2023-08-18T21:29:49.332904",
     "exception": false,
     "start_time": "2023-08-18T21:29:49.323873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tokenizing text and converting to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b53c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:29:49.352635Z",
     "iopub.status.busy": "2023-08-18T21:29:49.352321Z",
     "iopub.status.idle": "2023-08-18T21:31:10.682709Z",
     "shell.execute_reply": "2023-08-18T21:31:10.681237Z"
    },
    "papermill": {
     "duration": 81.354372,
     "end_time": "2023-08-18T21:31:10.696378",
     "exception": true,
     "start_time": "2023-08-18T21:29:49.342006",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 1 tokenizer = ElectraTokenizer.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">'google/electra-base-discriminator'</span>)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>max_seq_length = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">128</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#Use 512 for better results (if using GPU)</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1809</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1806 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1807 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1808 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">all</span>(full_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> full_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> resolved_vocab_files.values(  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1809 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1810 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Can't load tokenizer for '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}'. If you wer</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1811 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"'https://huggingface.co/models', make sure you don't have a local direc</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Otherwise, make sure '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}' is the correct </span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>Can't load tokenizer for <span style=\"color: #008000; text-decoration-color: #008000\">'google/electra-base-discriminator'</span>. If you were trying to load it from \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/models'</span>, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure <span style=\"color: #008000; text-decoration-color: #008000\">'google/electra-base-discriminator'</span> is the correct path to a directory containing all relevant files for a \n",
       "ElectraTokenizer tokenizer.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 1 tokenizer = ElectraTokenizer.from_pretrained(\u001b[33m'\u001b[0m\u001b[33mgoogle/electra-base-discriminator\u001b[0m\u001b[33m'\u001b[0m)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mmax_seq_length = \u001b[94m128\u001b[0m \u001b[2m#Use 512 for better results (if using GPU)\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m1809\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1806 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1807 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1808 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mall\u001b[0m(full_file_name \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m full_file_name \u001b[95min\u001b[0m resolved_vocab_files.values(  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1809 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCan\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt load tokenizer for \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. If you wer\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1811 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/models\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, make sure you don\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt have a local direc\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mOtherwise, make sure \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is the correct \u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0mCan't load tokenizer for \u001b[32m'google/electra-base-discriminator'\u001b[0m. If you were trying to load it from \n",
       "\u001b[32m'https://huggingface.co/models'\u001b[0m, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure \u001b[32m'google/electra-base-discriminator'\u001b[0m is the correct path to a directory containing all relevant files for a \n",
       "ElectraTokenizer tokenizer.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "\n",
    "max_seq_length = 128 #Use 512 for better results (if using GPU)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n",
    "\n",
    "data['text_tokens'] = data['text'].apply(tokenize_text)\n",
    "\n",
    "# Split the data into features and targets\n",
    "X = data['text_tokens'].tolist()\n",
    "y = data[['wording', 'content']].values\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train).to(device)\n",
    "X_test = torch.tensor(X_test).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332839f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Loaded Transformer model (Use either ELECTRA or BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad50b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:19:08.252445Z",
     "iopub.status.busy": "2023-08-18T21:19:08.252081Z",
     "iopub.status.idle": "2023-08-18T21:19:11.347590Z",
     "shell.execute_reply": "2023-08-18T21:19:11.346611Z",
     "shell.execute_reply.started": "2023-08-18T21:19:08.252397Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "base_model = ElectraModel.from_pretrained('google/electra-base-discriminator').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57860a31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Generate Embeddings (Use GPU to go brrrrrr...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc695e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:19:11.349564Z",
     "iopub.status.busy": "2023-08-18T21:19:11.349175Z",
     "iopub.status.idle": "2023-08-18T21:20:24.620566Z",
     "shell.execute_reply": "2023-08-18T21:20:24.619322Z",
     "shell.execute_reply.started": "2023-08-18T21:19:11.349531Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text_tokens):\n",
    "    embeddings_list = []\n",
    "    with tqdm(total=len(text_tokens)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for tokens in text_tokens:\n",
    "                outputs = base_model(tokens.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :]  # Extract embeddings for [CLS] token\n",
    "                embeddings_list.append(embeddings)\n",
    "                pbar.update(1)\n",
    "        embeddings_tensor = torch.cat(embeddings_list, dim=0)\n",
    "        return embeddings_tensor\n",
    "\n",
    "X_train_embeddings = generate_bert_embeddings(X_train)\n",
    "X_test_embeddings = generate_bert_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027d1cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Make a Regression model to predict Content Score and Wording Score - A simple MLP (Multi-layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf6cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:20:24.623681Z",
     "iopub.status.busy": "2023-08-18T21:20:24.623078Z",
     "iopub.status.idle": "2023-08-18T21:20:24.632572Z",
     "shell.execute_reply": "2023-08-18T21:20:24.631269Z",
     "shell.execute_reply.started": "2023-08-18T21:20:24.623642Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "#Defining a MCRMSE\n",
    "def mean_columnwise_rmse(y_pred, y_true):\n",
    "    columnwise_rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0))\n",
    "    return torch.mean(columnwise_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f577c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28816402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:20:24.634906Z",
     "iopub.status.busy": "2023-08-18T21:20:24.634483Z",
     "iopub.status.idle": "2023-08-18T21:20:24.654732Z",
     "shell.execute_reply": "2023-08-18T21:20:24.653563Z",
     "shell.execute_reply.started": "2023-08-18T21:20:24.634865Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = base_model.config.hidden_size\n",
    "hidden_dim = 256  # Adjust the hidden layer dimension as needed\n",
    "output_dim = 2  # Number of target variables\n",
    "model = RegressionModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10 # Run it for 100-150 epoch\n",
    "batch_size = 32 # 64 or 128 if using GPU\n",
    "\n",
    "train_dataset = TensorDataset(X_train_embeddings, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loss1_list = []\n",
    "train_loss2_list = []\n",
    "test_loss1_list = []\n",
    "test_loss2_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd31d4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64cb0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:20:24.656908Z",
     "iopub.status.busy": "2023-08-18T21:20:24.656478Z",
     "iopub.status.idle": "2023-08-18T21:20:28.108426Z",
     "shell.execute_reply": "2023-08-18T21:20:28.106627Z",
     "shell.execute_reply.started": "2023-08-18T21:20:24.656873Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss_wording = 0\n",
    "    total_loss_content = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_wording = criterion(outputs[:, 0], targets[:, 0])\n",
    "        loss_content = criterion(outputs[:, 1], targets[:, 1])\n",
    "\n",
    "        loss = (loss_wording + loss_content) / 2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss_wording += loss_wording.item()\n",
    "        total_loss_content += loss_content.item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    train_loss1_list.append(total_loss_wording / len(train_loader))\n",
    "    train_loss2_list.append(total_loss_content / len(train_loader))\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Wording Loss: {total_loss_wording:.4f}, Content Loss: {total_loss_content:.4f}, Loss: {total_loss:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_embeddings)\n",
    "        test_loss1 = criterion(test_outputs[:, 0], y_test[:, 0])\n",
    "        test_loss2 = criterion(test_outputs[:, 1], y_test[:, 1])\n",
    "        \n",
    "    test_loss1_list.append(test_loss1.item())\n",
    "    test_loss2_list.append(test_loss2.item())\n",
    "    \n",
    "    print(f'Test Loss Wording: {test_loss1_list[-1]:.4f}, Test Loss Content: {test_loss2_list[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc967a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Collect losses and save as CSV for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469db4ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:20:28.111811Z",
     "iopub.status.busy": "2023-08-18T21:20:28.111357Z",
     "iopub.status.idle": "2023-08-18T21:20:28.122089Z",
     "shell.execute_reply": "2023-08-18T21:20:28.120938Z",
     "shell.execute_reply.started": "2023-08-18T21:20:28.111775Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_data = {\n",
    "    'Epoch': list(range(1, num_epochs+1)),\n",
    "    'Train_Loss_Wording': train_loss1_list,\n",
    "    'Train_Loss_Content': train_loss2_list,\n",
    "    'Test_Loss_Wording': test_loss1_list,\n",
    "    'Test_Loss_Content': test_loss2_list\n",
    "}\n",
    "\n",
    "loss_df = pd.DataFrame(loss_data)\n",
    "loss_df.to_csv('losses.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad53b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Make submission ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf93d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:20:35.408148Z",
     "iopub.status.busy": "2023-08-18T21:20:35.407803Z",
     "iopub.status.idle": "2023-08-18T21:20:35.422951Z",
     "shell.execute_reply": "2023-08-18T21:20:35.421888Z",
     "shell.execute_reply.started": "2023-08-18T21:20:35.408122Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "test_data['text_tokens'] = test_data['text'].apply(tokenize_text)\n",
    "test_text_tokens = test_data['text_tokens'].tolist()\n",
    "test_text_tokens = torch.tensor(test_text_tokens).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95311d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:20:38.682321Z",
     "iopub.status.busy": "2023-08-18T21:20:38.681978Z",
     "iopub.status.idle": "2023-08-18T21:20:38.734699Z",
     "shell.execute_reply": "2023-08-18T21:20:38.733723Z",
     "shell.execute_reply.started": "2023-08-18T21:20:38.682294Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create embeddings for test data\n",
    "test_data_embeddings = generate_bert_embeddings(test_text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246e2d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:21:23.664204Z",
     "iopub.status.busy": "2023-08-18T21:21:23.663852Z",
     "iopub.status.idle": "2023-08-18T21:21:23.670156Z",
     "shell.execute_reply": "2023-08-18T21:21:23.669014Z",
     "shell.execute_reply.started": "2023-08-18T21:21:23.664175Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Predict scores for test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data_outputs = model(test_data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443030d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:25:12.121566Z",
     "iopub.status.busy": "2023-08-18T21:25:12.121191Z",
     "iopub.status.idle": "2023-08-18T21:25:12.129868Z",
     "shell.execute_reply": "2023-08-18T21:25:12.128903Z",
     "shell.execute_reply.started": "2023-08-18T21:25:12.121539Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a submission file\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df['student_id'] = test_data['student_id']\n",
    "submission_df['content'] = test_data_outputs[:, 1].cpu()\n",
    "submission_df['wording'] = test_data_outputs[:, 0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf0383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T21:26:09.179812Z",
     "iopub.status.busy": "2023-08-18T21:26:09.179435Z",
     "iopub.status.idle": "2023-08-18T21:26:09.186298Z",
     "shell.execute_reply": "2023-08-18T21:26:09.185092Z",
     "shell.execute_reply.started": "2023-08-18T21:26:09.179784Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30152f57",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Thanks! Do Upvote!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb99ea5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Will be sharing a notebook with additional features and more complex regression neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bda1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a35db1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c00056",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694bc83",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699f76e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63504d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32ce00",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fdc09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197836de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd140102",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "969aa89a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.878835,
   "end_time": "2023-08-18T21:31:14.219069",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-18T21:29:24.340234",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
